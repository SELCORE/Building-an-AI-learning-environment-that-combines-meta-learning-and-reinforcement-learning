{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**김동현이 4시간동안 쌈뽕하게 노력한 실험실**\n",
        "\n",
        "1. CartPole-v1 : 200 이상 나오게 노력중\n",
        "2. MountainCar-v0 : -110 이상 나오게 노력중\n",
        "3. Acrobot-v1 : -100 이상 나오게 노력중\n",
        "\n",
        "**결과값을 다 일일히 기록하느냐?**\n",
        "**- 그것이 간지니깐**"
      ],
      "metadata": {
        "id": "PoRUBq1PzffF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQi1WIsjWPJV",
        "outputId": "c55a6564-7a7f-4a91-c091-53c4ea92b29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torch gym numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical, Normal\n",
        "import numpy as np\n",
        "\n",
        "# 환경 설정\n",
        "environments = ['CartPole-v1', 'MountainCar-v0', 'Acrobot-v1']\n",
        "\n",
        "# 정책 네트워크 정의\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_space_type):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, action_dim)\n",
        "        self.action_space_type = action_space_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_action(self, state):\n",
        "        logits = self.forward(state)\n",
        "        if self.action_space_type == 'Discrete':\n",
        "            action_dist = Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action)\n",
        "        else:  # Box\n",
        "            action_dist = Normal(logits, torch.ones_like(logits) * 0.1)  # 0.1은 표준 편차 값\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action).sum()\n",
        "        return action, log_prob\n",
        "\n",
        "# 메타학습 (MAML) 함수\n",
        "def maml_update(env_name, state_dim, action_dim, action_space_type, meta_policy, meta_optimizer, inner_lr, train_episodes):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    inner_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    inner_policy.load_state_dict(meta_policy.state_dict())\n",
        "    inner_optimizer = optim.Adam(inner_policy.parameters(), lr=inner_lr)\n",
        "\n",
        "    # Inner loop (적응 단계)\n",
        "    for _ in range(train_episodes):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = inner_policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "            loss = -log_prob * reward\n",
        "            inner_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_optimizer.step()\n",
        "            state = next_state\n",
        "\n",
        "    # Meta update (메타학습 단계)\n",
        "    result = env.reset()  # state와 info를 분리하여 처리\n",
        "    state = result if isinstance(result, np.ndarray) else result[0]\n",
        "    done = False\n",
        "    meta_loss = 0\n",
        "    while not done:\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "        action, log_prob = inner_policy.get_action(state)\n",
        "        next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "        loss = -log_prob * reward\n",
        "        meta_loss += loss\n",
        "        state = next_state\n",
        "\n",
        "    meta_optimizer.zero_grad()\n",
        "    meta_loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "# 강화학습 (PPO) 함수\n",
        "def ppo_update(env_name, state_dim, action_dim, action_space_type, policy, optimizer, epochs, gamma=0.99, eps_clip=0.2):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        rewards, log_probs, states, actions = [], [], [], []\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "\n",
        "            rewards.append(reward)\n",
        "            log_probs.append(log_prob)\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # GAE와 PPO 손실 계산\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for reward in reversed(rewards):\n",
        "            discounted_sum = reward + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        returns = torch.tensor(returns, dtype=torch.float32)\n",
        "        log_probs = torch.stack(log_probs)\n",
        "\n",
        "        advantages = returns  # 간단화를 위해 값 함수 생략\n",
        "        new_log_probs = []\n",
        "        for state, action in zip(states, actions):\n",
        "            _, new_log_prob = policy.get_action(state)\n",
        "            new_log_probs.append(new_log_prob)\n",
        "        new_log_probs = torch.stack(new_log_probs)\n",
        "\n",
        "        ratio = torch.exp(new_log_probs - log_probs)\n",
        "\n",
        "        surr1 = ratio * advantages\n",
        "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantages\n",
        "        loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 메타학습 및 강화학습 수행\n",
        "meta_lr = 0.001\n",
        "inner_lr = 0.01\n",
        "train_episodes = 2  # 에피소드 수 줄이기\n",
        "test_episodes = 2  # 에피소드 수 줄이기\n",
        "epochs = 1  # 에폭 수 줄이기\n",
        "\n",
        "meta_policies = {}\n",
        "meta_optimizers = {}\n",
        "\n",
        "for env_name in environments:\n",
        "    env = gym.make(env_name)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_space_type = 'Discrete' if isinstance(env.action_space, gym.spaces.Discrete) else 'Box'\n",
        "    action_dim = env.action_space.n if action_space_type == 'Discrete' else env.action_space.shape[0]\n",
        "\n",
        "    # 각 환경에 맞는 메타 정책 네트워크 생성\n",
        "    meta_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    meta_optimizer = optim.Adam(meta_policy.parameters(), lr=meta_lr)\n",
        "\n",
        "    meta_policies[env_name] = meta_policy\n",
        "    meta_optimizers[env_name] = meta_optimizer\n",
        "\n",
        "for iteration in range(10):  # 반복 수 줄이기\n",
        "    for env_name in environments:\n",
        "        print(f\"Iteration {iteration+1}/10\")\n",
        "        print(f\"Updating environment: {env_name}\")\n",
        "\n",
        "        state_dim = meta_policies[env_name].fc1.in_features\n",
        "        action_dim = meta_policies[env_name].fc2.out_features\n",
        "        action_space_type = meta_policies[env_name].action_space_type\n",
        "\n",
        "        maml_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], inner_lr, train_episodes)\n",
        "        ppo_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], epochs)\n",
        "        print(f\"Finished updating environment: {env_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjyWsmx4WRK_",
        "outputId": "b230636c-0017-4010-92e9-ab3d57072b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 1/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 1/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 2/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 2/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 2/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 3/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 3/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 3/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 4/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 4/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 4/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 5/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 5/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 5/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 6/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 6/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 6/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 7/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 7/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 7/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 8/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 8/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 8/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 9/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 9/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 9/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 10/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 10/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 10/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_policy(env_name, policy, episodes=10):\n",
        "    env = gym.make(env_name)\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, _ = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if isinstance(env.action_space, gym.spaces.Discrete) else action.detach().numpy())\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    env.close()\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    std_reward = np.std(total_rewards)\n",
        "\n",
        "    return avg_reward, std_reward\n",
        "\n",
        "def plot_results(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    envs = list(results.keys())\n",
        "    avg_rewards = [results[env][0] for env in envs]\n",
        "    std_rewards = [results[env][1] for env in envs]\n",
        "\n",
        "    ax.barh(envs, avg_rewards, xerr=std_rewards, align='center')\n",
        "    ax.set_xlabel('Average Reward')\n",
        "    ax.set_title('Policy Performance in Different Environments')\n",
        "    plt.show()\n",
        "\n",
        "# 학습된 정책 평가\n",
        "results = {}\n",
        "for env_name in environments:\n",
        "    avg_reward, std_reward = evaluate_policy(env_name, meta_policies[env_name])\n",
        "    results[env_name] = (avg_reward, std_reward)\n",
        "    print(f\"Environment: {env_name}, Average Reward: {avg_reward}, Std: {std_reward}\")\n",
        "\n",
        "# 결과 시각화\n",
        "plot_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "NjbyhVSiyh5T",
        "outputId": "9d0653fa-2c42-428b-fe6b-0780556ec4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment: CartPole-v1, Average Reward: 18.0, Std: 10.353743284435827\n",
            "Environment: MountainCar-v0, Average Reward: -200.0, Std: 0.0\n",
            "Environment: Acrobot-v1, Average Reward: -500.0, Std: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical, Normal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 환경 설정\n",
        "environments = ['CartPole-v1', 'MountainCar-v0', 'Acrobot-v1']\n",
        "\n",
        "# 정책 네트워크 정의\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_space_type):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)  # 128에서 256으로 확장\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "        self.action_space_type = action_space_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_action(self, state):\n",
        "        logits = self.forward(state)\n",
        "        if self.action_space_type == 'Discrete':\n",
        "            action_dist = Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action)\n",
        "        else:  # Box\n",
        "            action_dist = Normal(logits, torch.ones_like(logits) * 0.1)  # 0.1은 표준 편차 값\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action).sum()\n",
        "        return action, log_prob\n",
        "\n",
        "# 메타학습 (MAML) 함수\n",
        "def maml_update(env_name, state_dim, action_dim, action_space_type, meta_policy, meta_optimizer, inner_lr, train_episodes):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    inner_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    inner_policy.load_state_dict(meta_policy.state_dict())\n",
        "    inner_optimizer = optim.Adam(inner_policy.parameters(), lr=inner_lr)\n",
        "\n",
        "    # Inner loop (적응 단계)\n",
        "    for _ in range(train_episodes):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = inner_policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "            loss = -log_prob * reward\n",
        "            inner_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_optimizer.step()\n",
        "            state = next_state\n",
        "\n",
        "    # Meta update (메타학습 단계)\n",
        "    result = env.reset()  # state와 info를 분리하여 처리\n",
        "    state = result if isinstance(result, np.ndarray) else result[0]\n",
        "    done = False\n",
        "    meta_loss = 0\n",
        "    while not done:\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "        action, log_prob = inner_policy.get_action(state)\n",
        "        next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "        loss = -log_prob * reward\n",
        "        meta_loss += loss\n",
        "        state = next_state\n",
        "\n",
        "    meta_optimizer.zero_grad()\n",
        "    meta_loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "# 강화학습 (PPO) 함수\n",
        "def ppo_update(env_name, state_dim, action_dim, action_space_type, policy, optimizer, epochs, gamma=0.99, eps_clip=0.2):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        rewards, log_probs, states, actions = [], [], [], []\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "\n",
        "            rewards.append(reward)\n",
        "            log_probs.append(log_prob)\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # GAE와 PPO 손실 계산\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for reward in reversed(rewards):\n",
        "            discounted_sum = reward + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        returns = torch.tensor(returns, dtype=torch.float32)\n",
        "        log_probs = torch.stack(log_probs)\n",
        "\n",
        "        advantages = returns  # 간단화를 위해 값 함수 생략\n",
        "        new_log_probs = []\n",
        "        for state, action in zip(states, actions):\n",
        "            _, new_log_prob = policy.get_action(state)\n",
        "            new_log_probs.append(new_log_prob)\n",
        "        new_log_probs = torch.stack(new_log_probs)\n",
        "\n",
        "        ratio = torch.exp(new_log_probs - log_probs)\n",
        "\n",
        "        surr1 = ratio * advantages\n",
        "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantages\n",
        "        loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 메타학습 및 강화학습 수행\n",
        "meta_lr = 0.001\n",
        "inner_lr = 0.01\n",
        "train_episodes = 5  # 에피소드 수 증가\n",
        "test_episodes = 5  # 에피소드 수 증가\n",
        "epochs = 3  # 에폭 수 증가\n",
        "\n",
        "meta_policies = {}\n",
        "meta_optimizers = {}\n",
        "\n",
        "for env_name in environments:\n",
        "    env = gym.make(env_name)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_space_type = 'Discrete' if isinstance(env.action_space, gym.spaces.Discrete) else 'Box'\n",
        "    action_dim = env.action_space.n if action_space_type == 'Discrete' else env.action_space.shape[0]\n",
        "\n",
        "    # 각 환경에 맞는 메타 정책 네트워크 생성\n",
        "    meta_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    meta_optimizer = optim.Adam(meta_policy.parameters(), lr=meta_lr)\n",
        "\n",
        "    meta_policies[env_name] = meta_policy\n",
        "    meta_optimizers[env_name] = meta_optimizer\n",
        "\n",
        "for iteration in range(10):\n",
        "    for env_name in environments:\n",
        "        print(f\"Iteration {iteration+1}/10\")\n",
        "        print(f\"Updating environment: {env_name}\")\n",
        "\n",
        "        state_dim = meta_policies[env_name].fc1.in_features\n",
        "        action_dim = meta_policies[env_name].fc3.out_features\n",
        "        action_space_type = meta_policies[env_name].action_space_type\n",
        "\n",
        "        maml_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], inner_lr, train_episodes)\n",
        "        ppo_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], epochs)\n",
        "        print(f\"Finished updating environment: {env_name}\")\n",
        "\n",
        "# 평가 함수 및 결과 시각화 함수\n",
        "def evaluate_policy(env_name, policy, episodes=10):\n",
        "    env = gym.make(env_name)\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, _ = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if isinstance(env.action_space, gym.spaces.Discrete) else action.detach().numpy())\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    env.close()\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    std_reward = np.std(total_rewards)\n",
        "\n",
        "    return avg_reward, std_reward\n",
        "\n",
        "def plot_results(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    envs = list(results.keys())\n",
        "    avg_rewards = [results[env][0] for env in envs]\n",
        "    std_rewards = [results[env][1] for env in envs]\n",
        "\n",
        "    ax.barh(envs, avg_rewards, xerr=std_rewards, align='center')\n",
        "    ax.set_xlabel('Average Reward')\n",
        "    ax.set_title('Policy Performance in Different Environments')\n",
        "    plt.show()\n",
        "\n",
        "# 학습된 정책 평가\n",
        "results = {}\n",
        "for env_name in environments:\n",
        "    avg_reward, std_reward = evaluate_policy(env_name, meta_policies[env_name])\n",
        "    results[env_name] = (avg_reward, std_reward)\n",
        "    print(f\"Environment: {env_name}, Average Reward: {avg_reward}, Std: {std_reward}\")\n",
        "\n",
        "# 결과 시각화\n",
        "plot_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsV7mIDZy9lH",
        "outputId": "1be1267e-901c-41c3-b9f1-457bc83f28ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 1/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 1/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 2/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 2/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 2/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 3/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 3/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 3/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 4/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 4/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 4/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 5/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 5/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 5/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 6/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 6/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 6/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 7/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 7/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 7/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 8/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 8/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 8/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 9/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 9/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 9/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 10/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 10/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 10/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Environment: CartPole-v1, Average Reward: 16.1, Std: 8.825531145489206\n",
            "Environment: MountainCar-v0, Average Reward: -200.0, Std: 0.0\n",
            "Environment: Acrobot-v1, Average Reward: -500.0, Std: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical, Normal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 환경 설정\n",
        "environments = ['CartPole-v1', 'MountainCar-v0', 'Acrobot-v1']\n",
        "\n",
        "# 정책 네트워크 정의\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_space_type):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)  # 128에서 256으로 확장\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "        self.action_space_type = action_space_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_action(self, state):\n",
        "        logits = self.forward(state)\n",
        "        if self.action_space_type == 'Discrete':\n",
        "            action_dist = Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action)\n",
        "        else:  # Box\n",
        "            action_dist = Normal(logits, torch.ones_like(logits) * 0.1)  # 0.1은 표준 편차 값\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action).sum()\n",
        "        return action, log_prob\n",
        "\n",
        "# 메타학습 (MAML) 함수\n",
        "def maml_update(env_name, state_dim, action_dim, action_space_type, meta_policy, meta_optimizer, inner_lr, train_episodes):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    inner_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    inner_policy.load_state_dict(meta_policy.state_dict())\n",
        "    inner_optimizer = optim.Adam(inner_policy.parameters(), lr=inner_lr)\n",
        "\n",
        "    # Inner loop (적응 단계)\n",
        "    for _ in range(train_episodes):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = inner_policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "            loss = -log_prob * reward\n",
        "            inner_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_optimizer.step()\n",
        "            state = next_state\n",
        "\n",
        "    # Meta update (메타학습 단계)\n",
        "    result = env.reset()  # state와 info를 분리하여 처리\n",
        "    state = result if isinstance(result, np.ndarray) else result[0]\n",
        "    done = False\n",
        "    meta_loss = 0\n",
        "    while not done:\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "        action, log_prob = inner_policy.get_action(state)\n",
        "        next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "        loss = -log_prob * reward\n",
        "        meta_loss += loss\n",
        "        state = next_state\n",
        "\n",
        "    meta_optimizer.zero_grad()\n",
        "    meta_loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "# 강화학습 (PPO) 함수\n",
        "def ppo_update(env_name, state_dim, action_dim, action_space_type, policy, optimizer, epochs, gamma=0.99, eps_clip=0.2):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        result = env.reset()  # state와 info를 분리하여 처리\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        rewards, log_probs, states, actions = [], [], [], []\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "\n",
        "            rewards.append(reward)\n",
        "            log_probs.append(log_prob)\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # GAE와 PPO 손실 계산\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for reward in reversed(rewards):\n",
        "            discounted_sum = reward + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        returns = torch.tensor(returns, dtype=torch.float32)\n",
        "        log_probs = torch.stack(log_probs)\n",
        "\n",
        "        advantages = returns  # 간단화를 위해 값 함수 생략\n",
        "        new_log_probs = []\n",
        "        for state, action in zip(states, actions):\n",
        "            _, new_log_prob = policy.get_action(state)\n",
        "            new_log_probs.append(new_log_prob)\n",
        "        new_log_probs = torch.stack(new_log_probs)\n",
        "\n",
        "        ratio = torch.exp(new_log_probs - log_probs)\n",
        "\n",
        "        surr1 = ratio * advantages\n",
        "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantages\n",
        "        loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 메타학습 및 강화학습 수행\n",
        "meta_lr = 0.001\n",
        "inner_lr = 0.01\n",
        "train_episodes = 10  # 에피소드 수 증가\n",
        "test_episodes = 10  # 에피소드 수 증가\n",
        "epochs = 5  # 에폭 수 증가\n",
        "\n",
        "meta_policies = {}\n",
        "meta_optimizers = {}\n",
        "\n",
        "for env_name in environments:\n",
        "    env = gym.make(env_name)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_space_type = 'Discrete' if isinstance(env.action_space, gym.spaces.Discrete) else 'Box'\n",
        "    action_dim = env.action_space.n if action_space_type == 'Discrete' else env.action_space.shape[0]\n",
        "\n",
        "    # 각 환경에 맞는 메타 정책 네트워크 생성\n",
        "    meta_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    meta_optimizer = optim.Adam(meta_policy.parameters(), lr=meta_lr)\n",
        "\n",
        "    meta_policies[env_name] = meta_policy\n",
        "    meta_optimizers[env_name] = meta_optimizer\n",
        "\n",
        "for iteration in range(10):\n",
        "    for env_name in environments:\n",
        "        print(f\"Iteration {iteration+1}/10\")\n",
        "        print(f\"Updating environment: {env_name}\")\n",
        "\n",
        "        state_dim = meta_policies[env_name].fc1.in_features\n",
        "        action_dim = meta_policies[env_name].fc3.out_features\n",
        "        action_space_type = meta_policies[env_name].action_space_type\n",
        "\n",
        "        maml_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], inner_lr, train_episodes)\n",
        "        ppo_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], epochs)\n",
        "        print(f\"Finished updating environment: {env_name}\")\n",
        "\n",
        "# 평가 함수 및 결과 시각화 함수\n",
        "def evaluate_policy(env_name, policy, episodes=10):\n",
        "    env = gym.make(env_name)\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, _ = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if isinstance(env.action_space, gym.spaces.Discrete) else action.detach().numpy())\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    env.close()\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    std_reward = np.std(total_rewards)\n",
        "\n",
        "    return avg_reward, std_reward\n",
        "\n",
        "def plot_results(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    envs = list(results.keys())\n",
        "    avg_rewards = [results[env][0] for env in envs]\n",
        "    std_rewards = [results[env][1] for env in envs]\n",
        "\n",
        "    ax.barh(envs, avg_rewards, xerr=std_rewards, align='center')\n",
        "    ax.set_xlabel('Average Reward')\n",
        "    ax.set_title('Policy Performance in Different Environments')\n",
        "    plt.show()\n",
        "\n",
        "# 학습된 정책 평가\n",
        "results = {}\n",
        "for env_name in environments:\n",
        "    avg_reward, std_reward = evaluate_policy(env_name, meta_policies[env_name])\n",
        "    results[env_name] = (avg_reward, std_reward)\n",
        "    print(f\"Environment: {env_name}, Average Reward: {avg_reward}, Std: {std_reward}\")\n",
        "\n",
        "# 결과 시각화\n",
        "plot_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yYXzNM_W0wvT",
        "outputId": "7747fc2d-6563-4456-a6b9-8a74b2944a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 1/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 1/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 2/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 2/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 2/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 3/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 3/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 3/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 4/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 4/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 4/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 5/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 5/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 5/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 6/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 6/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 6/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 7/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 7/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 7/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 8/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 8/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 8/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 9/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 9/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 9/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Iteration 10/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 10/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 10/10\n",
            "Updating environment: Acrobot-v1\n",
            "Finished updating environment: Acrobot-v1\n",
            "Environment: CartPole-v1, Average Reward: 16.5, Std: 3.4713109915419564\n",
            "Environment: MountainCar-v0, Average Reward: -200.0, Std: 0.0\n",
            "Environment: Acrobot-v1, Average Reward: -500.0, Std: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical, Normal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 환경 설정\n",
        "environments = ['CartPole-v1', 'MountainCar-v0', 'Acrobot-v1']\n",
        "\n",
        "# 정책 네트워크 정의\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_space_type):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, action_dim)\n",
        "        self.action_space_type = action_space_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "    def get_action(self, state):\n",
        "        logits = self.forward(state)\n",
        "        if self.action_space_type == 'Discrete':\n",
        "            action_dist = Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action)\n",
        "        else:\n",
        "            action_dist = Normal(logits, torch.ones_like(logits) * 0.1)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action).sum()\n",
        "        return action, log_prob\n",
        "\n",
        "# 메타학습 (MAML) 함수\n",
        "def maml_update(env_name, state_dim, action_dim, action_space_type, meta_policy, meta_optimizer, inner_lr, train_episodes):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    inner_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    inner_policy.load_state_dict(meta_policy.state_dict())\n",
        "    inner_optimizer = optim.Adam(inner_policy.parameters(), lr=inner_lr)\n",
        "\n",
        "    # Inner loop (적응 단계)\n",
        "    for _ in range(train_episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = inner_policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "            loss = -log_prob * reward\n",
        "            inner_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_optimizer.step()\n",
        "            state = next_state\n",
        "\n",
        "    # Meta update (메타학습 단계)\n",
        "    result = env.reset()\n",
        "    state = result if isinstance(result, np.ndarray) else result[0]\n",
        "    done = False\n",
        "    meta_loss = 0\n",
        "    while not done:\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "        action, log_prob = inner_policy.get_action(state)\n",
        "        next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "        loss = -log_prob * reward\n",
        "        meta_loss += loss\n",
        "        state = next_state\n",
        "\n",
        "    meta_optimizer.zero_grad()\n",
        "    meta_loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "# 강화학습 (PPO) 함수\n",
        "def ppo_update(env_name, state_dim, action_dim, action_space_type, policy, optimizer, epochs, gamma=0.99, eps_clip=0.2):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        rewards, log_probs, states, actions = [], [], [], []\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, log_prob = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if action_space_type == 'Discrete' else action.detach().numpy())\n",
        "\n",
        "            rewards.append(reward)\n",
        "            log_probs.append(log_prob)\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # GAE와 PPO 손실 계산\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for reward in reversed(rewards):\n",
        "            discounted_sum = reward + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        returns = torch.tensor(returns, dtype=torch.float32)\n",
        "        log_probs = torch.stack(log_probs)\n",
        "\n",
        "        advantages = returns\n",
        "        new_log_probs = []\n",
        "        for state, action in zip(states, actions):\n",
        "            _, new_log_prob = policy.get_action(state)\n",
        "            new_log_probs.append(new_log_prob)\n",
        "        new_log_probs = torch.stack(new_log_probs)\n",
        "\n",
        "        ratio = torch.exp(new_log_probs - log_probs)\n",
        "\n",
        "        surr1 = ratio * advantages\n",
        "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantages\n",
        "        loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 메타학습 및 강화학습 수행\n",
        "meta_lr = 0.0003\n",
        "inner_lr = 0.01\n",
        "train_episodes = 50  # 에피소드 수 대폭 증가\n",
        "test_episodes = 50\n",
        "epochs = 20  # 에폭 수 대폭 증가\n",
        "\n",
        "meta_policies = {}\n",
        "meta_optimizers = {}\n",
        "\n",
        "for env_name in environments:\n",
        "    env = gym.make(env_name)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_space_type = 'Discrete' if isinstance(env.action_space, gym.spaces.Discrete) else 'Box'\n",
        "    action_dim = env.action_space.n if action_space_type == 'Discrete' else env.action_space.shape[0]\n",
        "\n",
        "    meta_policy = PolicyNetwork(state_dim, action_dim, action_space_type)\n",
        "    meta_optimizer = optim.Adam(meta_policy.parameters(), lr=meta_lr)\n",
        "\n",
        "    meta_policies[env_name] = meta_policy\n",
        "    meta_optimizers[env_name] = meta_optimizer\n",
        "\n",
        "for iteration in range(10):\n",
        "    for env_name in environments:\n",
        "        print(f\"Iteration {iteration+1}/10\")\n",
        "        print(f\"Updating environment: {env_name}\")\n",
        "\n",
        "        state_dim = meta_policies[env_name].fc1.in_features\n",
        "        action_dim = meta_policies[env_name].fc4.out_features\n",
        "        action_space_type = meta_policies[env_name].action_space_type\n",
        "\n",
        "        maml_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], inner_lr, train_episodes)\n",
        "        ppo_update(env_name, state_dim, action_dim, action_space_type, meta_policies[env_name], meta_optimizers[env_name], epochs)\n",
        "        print(f\"Finished updating environment: {env_name}\")\n",
        "\n",
        "# 평가 함수 및 결과 시각화 함수\n",
        "def evaluate_policy(env_name, policy, episodes=10):\n",
        "    env = gym.make(env_name)\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, _ = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if isinstance(env.action_space, gym.spaces.Discrete) else action.detach().numpy())\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    env.close()\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    std_reward = np.std(total_rewards)\n",
        "\n",
        "    return avg_reward, std_reward\n",
        "\n",
        "def plot_results(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    envs = list(results.keys())\n",
        "    avg_rewards = [results[env][0] for env in envs]\n",
        "    std_rewards = [results[env][1] for env in envs]\n",
        "\n",
        "    ax.barh(envs, avg_rewards, xerr=std_rewards, align='center')\n",
        "    ax.set_xlabel('Average Reward')\n",
        "    ax.set_title('Policy Performance in Different Environments')\n",
        "    plt.show()\n",
        "\n",
        "# 학습된 정책 평가\n",
        "results = {}\n",
        "for env_name in environments:\n",
        "    avg_reward, std_reward = evaluate_policy(env_name, meta_policies[env_name])\n",
        "    results[env_name] = (avg_reward, std_reward)\n",
        "    print(f\"Environment: {env_name}, Average Reward: {avg_reward}, Std: {std_reward}\")\n",
        "\n",
        "# 결과 시각화\n",
        "plot_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NRznC-gN2mBp",
        "outputId": "6565b171-f3f3-49d4-e0f1-0b2f797565c1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/10\n",
            "Updating environment: CartPole-v1\n",
            "Finished updating environment: CartPole-v1\n",
            "Iteration 1/10\n",
            "Updating environment: MountainCar-v0\n",
            "Finished updating environment: MountainCar-v0\n",
            "Iteration 1/10\n",
            "Updating environment: Acrobot-v1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b3cdd173eb92>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0maction_space_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_policies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mmaml_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_policies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_policies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finished updating environment: {env_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-b3cdd173eb92>\u001b[0m in \u001b[0;36mmaml_update\u001b[0;34m(env_name, state_dim, action_dim, action_space_type, meta_policy, meta_optimizer, inner_lr, train_episodes)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0minner_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0minner_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 이후부터는 너무 오래걸려서 내가 하진 않겟다.\n",
        "내 시간은 소중하기 때문이다."
      ],
      "metadata": {
        "id": "kSpHnUoY-NxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습 환경 구축 방법**\n",
        "1. 도구 및 라이브러리: Gym, PyTorch\n",
        "2. 정책 네트워크 설계: 상태 공간과 행동 공간에 맞게 설계된 신경망\n",
        "3. 메타러닝 알고리즘 구현: MAML\n",
        "4. 강화학습 알고리즘 구현: PPO"
      ],
      "metadata": {
        "id": "ugExLC_00JBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 코드 예시: 정책 네트워크 정의\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_space_type):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "        self.action_space_type = action_space_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_action(self, state):\n",
        "        logits = self.forward(state)\n",
        "        if self.action_space_type == 'Discrete':\n",
        "            action_dist = Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action)\n",
        "        else:\n",
        "            action_dist = Normal(logits, torch.ones_like(logits) * 0.1)\n",
        "            action = action_dist.sample()\n",
        "            log_prob = action_dist.log_prob(action).sum()\n",
        "        return action, log_prob\n"
      ],
      "metadata": {
        "id": "j_e4hR-_0LbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**구축된 환경에서의 실험**\n",
        "1. 환경 설정: CartPole-v1, MountainCar-v0, Acrobot-v1.\n",
        "2. 훈련 과정: MAML을 통한 메타학습과 PPO를 통한 강화학습 수행.\n",
        "3. 성능 평가: 각 환경에서의 평균 보상과 표준 편차 측정"
      ],
      "metadata": {
        "id": "M3YRw89O0eVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 평가 함수 예시\n",
        "def evaluate_policy(env_name, policy, episodes=10):\n",
        "    env = gym.make(env_name)\n",
        "    total_rewards = []\n",
        "    for episode in range(episodes):\n",
        "        result = env.reset()\n",
        "        state = result if isinstance(result, np.ndarray) else result[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            action, _ = policy.get_action(state)\n",
        "            next_state, reward, done, info = env.step(action.item() if isinstance(env.action_space, gym.spaces.Discrete) else action.detach().numpy())\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "        total_rewards.append(total_reward)\n",
        "    env.close()\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    std_reward = np.std(total_rewards)\n",
        "    return avg_reward, std_reward\n"
      ],
      "metadata": {
        "id": "AL6qWiel0qtn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}